# -*- coding: utf-8 -*-
"""Skripsi (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17BskQrMrqjSVLbhduHZFDEtMnX-_kXFD

Create Graph
"""

from google.colab import drive
drive.mount('/content/drive')

"""MAKING GRAPH"""

import networkx as nx             # graph
import matplotlib.pyplot as plt   # plot
import seaborn as sns
import numpy as np                # calculation
import pandas as pd
import copy as copy

# create Directed Graph
def cre_DiGraph(df, origin_col='origin', destination_col='destination', 
                distance_col='distance', exclude_selfloop=True):
    origins = df[origin_col].tolist()
    destinations = df[destination_col].tolist()
    distances = df[distance_col].tolist()
    # Making a Adjacency matrix
    g = nx.DiGraph()
    for o,d,f in zip(origins, destinations, distances):
        g.add_edge(o, d, weight=float(f))

    pos = nx.spring_layout(g)
    # Save graph as picture
    nx.draw(g, with_labels = True, pos = pos)
    plt.savefig("Graph.png")

    print('Graph Construction Succeed,'+' No. Nodes : '+str( g.number_of_nodes()) +', No. Edges : '+str(g.number_of_edges()))
    print(g.nodes())

    print('===' * 20)
    print('...' * 20)
    print('===' * 20)
    return g

#read OD Matrix
matrix = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/OD Matrix 83,25 KM.csv', index_col = 0)

#print(matrix)
# Creating the graph
graph = cre_DiGraph(matrix)

"""MODELLING"""

# Creating OD Matrix for modelling
dist = nx.to_numpy_matrix(graph, weight = 'weight')
OD = nx.to_numpy_matrix(graph)
print(OD)

# DDPR algorithm
def run_ddpr(g, b=0.8, number_of_loops=1000, exfac=None) :
    N_Count = g.number_of_nodes()

    # Initial PageRank Score
    ranks = np.array(np.ones((1, N_Count)) / float(N_Count)).transpose() 
    print('Preparation Done, Start Iterating...')
    #print(ranks)

    # Origin-Destination matrix
    MatrixOD = nx.to_numpy_matrix(g, weight = 'weight')  
    #MatrixODSum = MatrixOD.sum(axis=0)  # Sum every column (outdegree)

    # Preparing matrix for distance-decay effect
    MatrixDD = np.zeros((N_Count,N_Count)) 
    # Preparing matrix for partition score
    MatrixPart = np.zeros((N_Count,N_Count))

    # Looping to defining distance-decay effect
    for i in range(MatrixDD.shape[0]):
        for j in range(MatrixDD.shape[1]):

            #defining distance-decay effect
            if MatrixOD[i,j] > 0 :

              denominator = float(MatrixOD[i, j])
              MatrixDD[i, j] = 1 / (denominator) ** b
    #print(MatrixDD)
    # Defining sum of distance-decay effect of each node
    MatrixDDSum = MatrixDD.sum(axis=0)
    #print(MatrixDDSum)

    # Looping to defining matrix for partition score
    for i in range(MatrixPart.shape[0]):
        for j in range(MatrixPart.shape[1]):
          if MatrixOD[i,j] > 0 :
            x = float(MatrixDD[i,j])
            y = float(MatrixDDSum[j])
            MatrixPart[i,j] = x / y

    # Calculate DDPR score
    for i in range(1, number_of_loops + 1):
        old_ranks = copy.copy(ranks)
        ranks = np.matmul(MatrixPart, ranks)

        # Equillibrium until convergence
        if np.ma.allclose(ranks, old_ranks): break

    print('Calculation Done After Iteration : ' + str(i))
    print('With b = ' + str(b))

    # Represent DDPR score as dictionary format
    value = [i[0] for i in ranks.tolist()]
    key = list(g.nodes())

    ddprScore = {}
    for i in range(len(ranks)):
        ddprScore[key[i]] = value[i]

    nama = key
    skor = value

    print('===' * 20)
    print('===' * 20)


    dictionary = dict(reversed(sorted(ddprScore.items(), 
                                      key = lambda item: item[1])))

    for key, value in dictionary.items():
        print("{} : ({})".format(key, value))

    plt.rcdefaults()
    fig, ax = plt.subplots()

    ax.barh(nama, skor, align='center')
    ax.set_yticks(np.arange(len(nama)))
    ax.set_yticklabels(nama)
    ax.invert_yaxis()  # labels read top-to-bottom
    ax.set_xlabel('Score')
    ax.set_title('DDPR Score')

    plt.show()

    list1 = [ddprScore, b, nama, skor]

    return list1

# Function for making a dictionary
def makeDict(dfCases, origin_col='node', destination_col='cases'):
   nodes = dfCases[origin_col].tolist()
   cases = dfCases[destination_col].tolist()
   result = dict(zip(nodes, cases))
   
   return result 

from scipy.stats import pearsonr   

# Pearson Correlation
def pearsonCorr(var1, var2):
   val1_list = []

   for key, val1 in sorted(var1.items()):
       val1_list.append(val1)

   val2_list = []

   for key, val2 in sorted(var2.items()):
       val2_list.append(val2)

   corr, p_value = pearsonr(val1_list, val2_list)
   print("Nilai Korelasi : ", corr)

   return corr

"""Parameter Tuning"""

# Read the file of Penumpang (human movement)
penumpang = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/Penumpang - Sheet1.csv', 
                     index_col = 0)
human = makeDict(penumpang)
human

# Parameter tuning on distance factor variable

korelasi = []
distanceFactor = []
for i in np.arange(0, 10.0, 0.1) :
  score = run_ddpr(graph, b=i)
  print(" ")
  corr = pearsonCorr(score[0],human)
  print(" ")
  distanceFactor.append(score[1])
  korelasi.append(corr)

# Making the plot of distance factor and Coeff Correlation

fig, ax = plt.subplots()
ax.plot(distanceFactor, korelasi)

ax.set(xlabel='Distance Factor', ylabel='Coefficent of Correlation')
ax.grid()

plt.show()

#harus ngeluarin nilai beta maksnya aja

"""DDPR modelling with maximum correlated distance factor"""

score = run_ddpr(graph)

# Maximum correlation of score and human movement 
corr = pearsonCorr(score[0], human)

scores = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/Skor.csv')
scores['Nama'] = scores['Nama Stasiun']

sns.set_theme(style="darkgrid")
sns.regplot(x="kasus", y="skor", data=scores);

# basic plot
sns.regplot(data=scores, x="kasus", y="skor", fit_reg=False, marker="o", color="skyblue", scatter_kws={'s':400})
 
# add annotations one by one with a loop
for line in range(0,df.shape[0]):
     plt.text(scores.kasus[line]-1, scores.skor[line]+.007, scores.Nama[line], horizontalalignment='left', size='small', color='black')

plt.show()

ax = sns.lmplot(x="kasus", y="skor", data=scores, fit_reg=False, # Don't fix a regression line
           height = 8,
           aspect =2 ) # size and dimension


# Set x-axis label
plt.xlabel('COVID-19 Cases')
# Set y-axis label
plt.ylabel('DDPR Score')


def label_point1(x, y, val, ax):
    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)
    for i, point in a.iterrows():
        ax.text(point['x'], point['y']+.003, str(point['val']))
    
    #plt.savefig("scatter_covid.png")

label_point1(scores['kasus'], scores['skor'], scores['Nama Stasiun'], plt.gca())

# basic plot
sns.regplot(data=scores, x="Cases", y="Nilai Skor DDPR", fit_reg=False, marker="o", color="skyblue", scatter_kws={'s':400})
 
# add annotations one by one with a loop
for line in range(0,scores.shape[0]):
     plt.text(scores['Cases']+0.2, scores['Nilai Skor DDPR'], scores['Nama Stasiun'], horizontalalignment='left', size='medium', color='black', weight='semibold')

plt.show()

score_penum = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/skor-penumpang - Sheet1.csv')

ax = sns.lmplot(x="penumpang", y='skor', data=score_penum, fit_reg=False, # Don't fix a regression line
           height = 8,
           aspect =2 ) # size and dimension

# Set x-axis label
plt.xlabel('Avarage passenger')
# Set y-axis label
plt.ylabel('DDPR Score')


def label_point(x, y, val, ax):
    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)
    for i, point in a.iterrows():
        ax.text(point['x']-.02, point['y']+.002, str(point['val']))

    plt.savefig("scatter.png")

label_point(score_penum['penumpang'], score_penum['skor'], score_penum['Nama Stasiun'], plt.gca())

ax = sns.lmplot(x="avg_jarak", y="skor", data=scores, fit_reg=False, # Don't fix a regression line
           height = 8,
           aspect =2 ) # size and dimension


# Set x-axis label
plt.xlabel('COVID-19 Cases')
# Set y-axis label
plt.ylabel('DDPR Score')


def label_point1(x, y, val, ax):
    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)
    for i, point in a.iterrows():
        ax.text(point['x'], point['y']+.003, str(point['val']))
    
    #plt.savefig("scatter_covid.png")

label_point1(scores['avg_jarak'], scores['skor'], scores['Nama Stasiun'], plt.gca())

"""PEARSON'S CORRELATION ANALYSIS"""

# Finding the correlation between score and COVID-19 cases
data = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/Covid-19 Jatim Kereta_22 Juni.csv', 
                     index_col = 0)

case = makeDict(data)
#print(cases)
corr = pearsonCorr(score[0],case)

"""VISUALIZATION"""

# Collecting the score for visualization
Size = [element * 1000 for element in score[3]]
Skor = score[3]

from pandas import DataFrame
df = DataFrame(score[2],columns=['Nama'])
df['Skor'] = Skor
df['stasiun']=df['Nama']
df['size'] = Size
df

! pip install geopandas
! pip install geoplot
! pip install plotly_express

import geoplot as gplt
import geopandas as gpd
import geoplot.crs as gcrs
import imageio
import pathlib
import mapclassify as mc
import plotly_express as px


jatim = gpd.read_file('/content/drive/MyDrive/Skripsi/jatim/Batas_Wilayah_Administrasi__Area_.shp')[['WADMKK', 'geometry']]
jatim.head()

jatim.plot()

# Read file
covid = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/Data Covid Jawa Timur (per 15 April 2021) - Sheet1.csv', 
                     index_col = 0)
covid.head()

# Merging the dataframe
merged = jatim.set_index("WADMKK").join(covid.set_index("node"))
merged.head()

# Heatmap for COVID case

# set a variable that will call whatever column we want to visualise on the map
variable = 'cases'
# set the range for the choropleth
vmin, vmax = 1000, 23500
# create figure and axes for Matplotlib
fig, ax = plt.subplots(1, figsize=(10, 6))

ax.axis('off')

# add a title
ax.set_title('COVID-19 Cases on East Java', fontdict={'fontsize': '20', 'fontweight' : '3'})

# Create colorbar as a legend
sm = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=vmin, vmax=vmax))
# empty array for the data range
sm._A = []
# add the colorbar to the figure
cbar = fig.colorbar(sm)

# create map
merged.plot(column=variable, cmap='Reds', linewidth=0.8, ax=ax, edgecolor='0.8')

fig.savefig('map_covid.png', dpi=300)

#Bubble plot score-covid

# Read the file
titik = gpd.read_file('/content/drive/MyDrive/Skripsi/jatim/titik.shp')[['Nama', 'geometry']]
titik.head()

jatimSampled = gpd.read_file('/content/drive/MyDrive/Skripsi/jatim/jatim.shp')[['WADMKK', 'geometry']]

covidBubble = pd.read_csv('/content/drive/MyDrive/Skripsi/Data/Covid-19 Jatim Kereta_22 Juni.csv', 
                     index_col = 0)

df['cases']=covidBubble['cases']
#df.head()

# Merging the data
mergedBubble = titik.set_index("Nama").join(df.set_index("Nama"))

mergedBubble

fig, ax = plt.subplots(figsize=(12,8))
jatimSampled.plot(ax=ax, color="lightgray", edgecolor="grey", linewidth=0.4)
mergedBubble.plot(ax=ax,color="#07424A", markersize="size",alpha=0.7, categorical=False, legend=True )

# add a title
ax.set_title('DDPR Score Per Station', fontdict={'fontsize': '20', 'fontweight' : '3'})

ax.axis("off")
plt.axis('equal')
plt.show()

fig.savefig('map_bubble.png', dpi=300)

titik_4326 = mergedBubble.to_crs("EPSG:4326")

fig = px.scatter_mapbox(
                        titik_4326, 
                        lat=titik_4326.geometry.y, 
                        lon=titik_4326.geometry.x, 
                        size="Skor", 
                        color="cases", 
                        hover_name = "stasiun",
                        color_continuous_scale=px.colors.sequential.turbid,  
                        size_max=50, 
                        zoom=10 )

fig.update_layout(mapbox_style = "open-street-map")
fig.update_layout(margin = {"r" : 0, "t" : 0, "l" : 0, "b" : 0})
fig.update_layout(autosize = True, hovermode = 'closest')

                    
fig.show()

"""Head tail breaks"""

def htbreak(adic, g=3):
    alist = [ v for k,v in adic.items() ]
    temp = copy.copy(alist)
    breaks = []
    for i in range(g-1):
        avg = sum(temp) / float(len(temp))
        breaks.append(avg)
        temp2 = [ v for v in temp if v>avg ]
        temp = temp2
    #alist2 = []
    adic2 = {}
    for k,v in adic.items():
        lvl = None
        for i in range(len(breaks)):
            if v<=breaks[i]:
                lvl = i
                break
        if lvl is None:
            lvl = len(breaks)
        #alist2.append(lvl)
        adic2[k] = lvl

    #print(alist2)
    return adic2, breaks

htbreak(score[0])

htbreak(case)